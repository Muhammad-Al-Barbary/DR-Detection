{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "import cv2 \n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras import callbacks \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5to9sHyWOA5",
        "outputId": "413f1c92-02aa-4acf-ad51-031cf5dcd6ed"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "KAsC9yLs6l_X",
        "outputId": "f823218e-2442-4db2-ee9f-12e78983e3c7"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"\"\n",
        "!kaggle competitions download -c diabetic-retinopathy-detection -f train.zip.002\n",
        "!kaggle competitions download -c diabetic-retinopathy-detection -f trainLabels.csv.zip\n",
        "! unzip \"trainLabels.csv.zip\"\n",
        "! unzip \"train.zip.002.zip\"\n",
        "!apt install p7zip-full -y\n",
        "!7z x train.zip.002\n",
        "!ls train | wc -l #print number of images\n",
        "!ls train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6MgAeFEzqgA",
        "outputId": "3192ee5d-1800-4dd7-a62f-4cb42f26eec2"
      },
      "outputs": [],
      "source": [
        "base_image_dir = \"/content/train\"\n",
        "retina_df = pd.read_csv(\"/content/trainLabels.csv\")\n",
        "retina_df['PatientId'] = retina_df['image'].map(lambda x: x.split('_')[0])\n",
        "retina_df['path'] = retina_df['image'].map(lambda x: os.path.join(base_image_dir,\n",
        "                                                         '{}.jpeg'.format(x)))\n",
        "retina_df['exists'] = retina_df['path'].map(os.path.exists)\n",
        "print(retina_df['exists'].sum(), 'images found of', retina_df.shape[0], 'total')\n",
        "retina_df['eye'] = retina_df['image'].map(lambda x: 1 if x.split('_')[-1]=='left' else 0)\n",
        "retina_df['level_cat'] = retina_df['level'].map(lambda x: to_categorical(x, 1+retina_df['level'].max()))\n",
        "\n",
        "retina_df.dropna(inplace = True)\n",
        "retina_df = retina_df[retina_df['exists']]\n",
        "retina_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "L7uSXfqSqXEq",
        "outputId": "e49816c1-8a36-4900-89ba-e4b16325a883"
      },
      "outputs": [],
      "source": [
        "def balance_data(class_size,df):\n",
        "    train_df = df.groupby(['level']).apply(lambda x: x.sample(class_size, replace = True)).reset_index(drop = True)\n",
        "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "    print('New Data Size:', train_df.shape[0], 'Old Size:', df.shape[0])\n",
        "    train_df['level'].hist(figsize = (10, 5))\n",
        "    return train_df\n",
        "train_df = balance_data(2000,retina_df) # I will oversample such that all classes have the same number of images as the maximum\n",
        "retina_df.pivot_table(index='level', aggfunc=len)\n",
        "train_df.pivot_table(index='level', aggfunc=len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqTr4BPSslqf",
        "outputId": "fb102304-d1dc-4916-b0bb-6103a35771b4"
      },
      "outputs": [],
      "source": [
        "def get_label_and_image(path):\n",
        "  name= path.split('/')[-1].split('.')[0]\n",
        "  print(path,name)\n",
        "\n",
        "  label=train_df[\"level_cat\"].loc[train_df['image'] == name].values[0]\n",
        "  print(label)\n",
        "  image=Image.open(path)\n",
        "  return image,label\n",
        "image,label=get_label_and_image(\"/content/train/38791_left.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds={\"image\":[],\n",
        "            \"label\":[]}\n",
        "\n",
        "paths=train_df[\"path\"]\n",
        "i=0\n",
        "for path in paths:\n",
        "  image,label=get_label_and_image(path)\n",
        "  train_ds[\"image\"].append(image)\n",
        "  train_ds[\"label\"].append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "Ncb2vHrP3sNY",
        "outputId": "49f3750b-fc30-4989-87d0-6351af580a76"
      },
      "outputs": [],
      "source": [
        "#data visualization\n",
        "f, axarr = plt.subplots(2,2, figsize=(10, 10))\n",
        "\n",
        "axarr[0,0].imshow(Image.open(\"/content/train/876_left.jpeg\"))\n",
        "axarr[0,0].set_title(\"level:\"+str(retina_df[\"level\"].loc[retina_df['image'] == \"876_left\"].values[0])) \n",
        "\n",
        "axarr[0,1].imshow(Image.open(\"/content/train/9203_left.jpeg\"))\n",
        "axarr[0,1].set_title(\"level:\"+str(retina_df[\"level\"].loc[retina_df['image'] == \"9203_left\"].values[0])) \n",
        "\n",
        "axarr[1,0].imshow(Image.open(\"/content/train/9977_right.jpeg\"))\n",
        "axarr[1,0].set_title(\"level:\"+str(retina_df[\"level\"].loc[retina_df['image'] == \"9977_right\"].values[0])) \n",
        "\n",
        "axarr[1,1].imshow(Image.open(\"/content/train/963_right.jpeg\"))\n",
        "axarr[1,1].set_title(\"level:\"+str(retina_df[\"level\"].loc[retina_df['image'] == \"963_right\"].values[0])) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV4qzHkVWHkj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8UIXltFWHko"
      },
      "outputs": [],
      "source": [
        "\n",
        "ptm = InceptionResNetV2(\n",
        "        input_shape = (100,100,3),\n",
        "        weights = 'imagenet',\n",
        "        include_top = False,\n",
        "        pooling='max',\n",
        ")\n",
        "ptm.trainable = True\n",
        "K = 5\n",
        "x = Flatten()(ptm.output)\n",
        "x = Dense(K, activation = 'softmax')(x)\n",
        "model = Model(inputs = ptm.input , outputs = x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C0Tcq-eWHkp"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqXAPl_VWHkp",
        "outputId": "a8ff3aa3-6ee7-402a-acbe-3ecc5b1b66a6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# custom_early_stopping = EarlyStopping(\n",
        "#     monitor='val_loss', \n",
        "#     patience=19, \n",
        "#     restore_best_weights=False)\n",
        "\n",
        "# save_checkpoint_cb= callbacks.ModelCheckpoint(\n",
        "#                       filepath='/content/drive/MyDrive/Biometrics Project/IRCP/IRCP', \n",
        "#                       save_freq='epoch', verbose=0,save_weights_only=True)\n",
        "\n",
        "history=model.fit(\n",
        "        x=train_images,\n",
        "        y=train_labels,\n",
        "        validation_data = (valid_images,valid_labels),\n",
        "        epochs = 15,\n",
        "        shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "erdGLZ76psZh",
        "outputId": "6d9f21ab-6206-4de3-9807-f65d6613904a"
      },
      "outputs": [],
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'][:2]+history.history['accuracy'][4:14])\n",
        "plt.plot(history.history['val_accuracy'][:2]+history.history['val_accuracy'][4:14])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'][:2]+history.history['loss'][4:14])\n",
        "plt.plot(history.history['val_loss'][:2]+history.history['val_loss'][4:14])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijSpXzrO49Sv"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR1GTUX5EgzW",
        "outputId": "c55e0b33-1f00-4d01-9fd9-5de0197c79b8"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_images,test_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
